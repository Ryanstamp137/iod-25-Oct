{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fix0Ry0j1qn5"
   },
   "source": [
    "<div>\n",
    "<img src=https://www.institutedata.com/wp-content/uploads/2019/10/iod_h_tp_primary_c.svg width=\"300\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U7WTDbVT1qn9"
   },
   "source": [
    "# Lab 9.2: CNN with Keras\n",
    "INSTRUCTIONS:\n",
    "- Read the guides and hints, then create the necessary analysis and code to find an answer and conclusion for the task below.\n",
    "- A guide you are encouraged to read through is TensorFlow's own tutorial for image classification, which can be found [here](https://www.tensorflow.org/tutorials/images/cnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EWGurboj1qoA"
   },
   "source": [
    "## CIFAR10 small image classification\n",
    "- [CIFAR10](https://www.cs.toronto.edu/~kriz/cifar.html) dataset of color training images, labeled over 10 categories.\n",
    "\n",
    "It has the classes:\n",
    "- airplane\n",
    "- automobile\n",
    "- bird\n",
    "- cat\n",
    "- deer\n",
    "- dog\n",
    "- frog\n",
    "- horse\n",
    "- ship\n",
    "- truck"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ee2ul0ED1qoD"
   },
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "c-pCdtFw1qoF"
   },
   "outputs": [],
   "source": [
    "# Uncomment the statements below if there are problems with TensorFlow on macOS\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "TQgN2_6D1qoN"
   },
   "outputs": [],
   "source": [
    "# insert code here\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "OohPiooS1qoQ"
   },
   "outputs": [],
   "source": [
    "# Uncomment the statement below to allow online monitoring with TensorBoard (need to be installed)\n",
    "from keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BAWeroBa1qoS"
   },
   "source": [
    "## Load data\n",
    "Use the **Keras**' load method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "F-Swb4TS1qoT"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cifar10' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13288\\3243939533.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# insert code here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;33m(\u001b[0m\u001b[0mX_train_all\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt_train_all\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mX_test_all\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt_test_all\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcifar10\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'cifar10' is not defined"
     ]
    }
   ],
   "source": [
    "# insert code here\n",
    "\n",
    "(X_train_all, t_train_all), (X_test_all, t_test_all) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_all' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13288\\2838596271.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0msize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m50000\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mX_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train_all\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mt_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt_train_all\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_test_all\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mt_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt_test_all\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train_all' is not defined"
     ]
    }
   ],
   "source": [
    "size = 50000\n",
    "X_train = X_train_all[:size,:,:,:]\n",
    "t_train = t_train_all[0:size,:]\n",
    "X_test = X_test_all[0:size,:,:,:]\n",
    "t_test = t_test_all[0:size,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = (\n",
    "    'plane',\n",
    "    'car',\n",
    "    'bird',\n",
    "    'cat',\n",
    "    'deer',\n",
    "    'dog',\n",
    "    'frog',\n",
    "    'horse',\n",
    "    'ship',\n",
    "    'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bLdYg4g41qoX"
   },
   "source": [
    "## Check some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Swf_e6CR1qoY"
   },
   "outputs": [],
   "source": [
    "# insert code here\n",
    "def check_one(data, label, id = None, actual = None, compare = False):\n",
    "    # check one\n",
    "    if id is None:\n",
    "        id = np.random.randint(data.shape[0])\n",
    "    im = data[id]\n",
    "    plt.figure(figsize = (3, 3))\n",
    "    plt.imshow(im)\n",
    "    \n",
    "    l_id = label[id]\n",
    "    if (compare) and (actual is not None) and (l_id != np.argmax(actual[id])):\n",
    "        a_id = np.argmax(actual[id])\n",
    "        plt.title('Class %d (%s) [\\u2260 %d-%s]' % (l_id, classes[l_id], a_id, classes[a_id]))\n",
    "    else:\n",
    "        plt.title('Class %d (%s)' % (l_id, classes[l_id]))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_ten(data, label, actual = None, compare = False):\n",
    "    # check ten\n",
    "    fig, ax = plt.subplots(2, 5, figsize = (11, 5))\n",
    "    fig.subplots_adjust(left = 0.02, right = 0.98, top = 0.8, wspace = 0.2, hspace = 0.2)\n",
    "    fig.suptitle('Check Data', fontsize = 12, fontweight = 'bold')\n",
    "\n",
    "    plt.rcParams.update({'font.size': 10})\n",
    "\n",
    "    ids = np.random.randint(data.shape[0], size = 10)\n",
    "    r = 0\n",
    "    c = 0\n",
    "    for id in ids:\n",
    "        im = data[id]\n",
    "\n",
    "        # original image\n",
    "        ax[r, c].imshow(im)\n",
    "        l_id = label[id]\n",
    "        if (compare) and (actual is not None) and (l_id != np.argmax(actual[id])):\n",
    "            a_id = np.argmax(actual[id])\n",
    "            ax[r, c].set_title('Class %d (%s) [\\u2260 %d-%s]' % (l_id, classes[l_id], a_id, classes[a_id]))\n",
    "        else:\n",
    "            ax[r, c].set_title('Class %d (%s)' % (l_id, classes[l_id]))\n",
    "        ax[r, c].set_xticks([])\n",
    "        ax[r, c].set_yticks([])\n",
    "        c += 1\n",
    "        if c > 4:\n",
    "            r += 1\n",
    "            c = 0\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_one(X_train, t_train.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_ten(X_train, t_train.flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N-Jhbjf11qob"
   },
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L9kdVXHd1qoc"
   },
   "outputs": [],
   "source": [
    "# insert code here\n",
    "_, img_rows, img_cols, img_channels = X_train.shape\n",
    "num_classes = len(set(t_train.flatten()))\n",
    "\n",
    "y_train = to_categorical(\n",
    "    t_train,\n",
    "    num_classes = num_classes,\n",
    "    dtype = 'uint8')\n",
    "y_test = to_categorical(\n",
    "    t_test,\n",
    "    num_classes = num_classes,\n",
    "    dtype = 'uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m2GU1EyK1qoe"
   },
   "source": [
    "## Create the model's architecture\n",
    "- **NOTE ALERT**: Take into account the volume of data and parameters. Time and processing escalate quite fast.\n",
    "- **NOTE ALERT**: It is likely this data will require more complex models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "82J0lM7d1qoe"
   },
   "outputs": [],
   "source": [
    "# insert code here\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dyq0xqGd1qoh"
   },
   "source": [
    "## Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zSv44CjG1qoh"
   },
   "outputs": [],
   "source": [
    "# insert code here\n",
    "model.compile(optimizer = 'adam', \n",
    "              loss = 'categorical_crossentropy', \n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "27wG0lYH1qoj"
   },
   "source": [
    "## Fit the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z8gUYh3n1qoj"
   },
   "outputs": [],
   "source": [
    "# Uncomment the statement below to allow online monitoring with TensorBoard\n",
    "tensorboard = TensorBoard(log_dir = 'logs') # choose or create a directory for the logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0ux6Ss1h1qok"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# insert code here\n",
    "\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    validation_split = 0.2,\n",
    "    epochs = 100,\n",
    "    batch_size = 100,\n",
    "    callbacks = [tensorboard],\n",
    "    verbose = 0)\n",
    "print(f'Training accuracy:{history.history[\"accuracy\"][-1]:.2f} validation accuracy:{history.history[\"val_accuracy\"][-1]:.2f} ')\n",
    "\n",
    "# cdgddgcvdgeygdcvdgyegdcvgdeygdcvdgeydgcvdgeygdcvdgeydgcvgdyedgcv\n",
    "# ..., callbacks = [tensorboard], ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PCL-erlE1qol"
   },
   "source": [
    "### TensorBoard\n",
    "- TensorBoard is TensorFlow's visualisation toolkit. \n",
    "- If Tensorflow 2 and Jupyter is installed in the same environment, running the cell below will start TensorBoard within the notebook.\n",
    "- More information about how to set up TensorBoard can be found [here](https://www.tensorflow.org/tensorboard/tensorboard_in_notebooks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_SC1MnqpABBQ"
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tQ_vBEpk1qom"
   },
   "source": [
    "## Create predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EuVMau111qon"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "predictions = model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2lA8OW9e1qop"
   },
   "source": [
    "## Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CjKr29mZ1qoq"
   },
   "outputs": [],
   "source": [
    "# insert code here\n",
    "score = model.evaluate(X_test, y_test, batch_size = 10)\n",
    "print('\\nTest loss: %.6f, Test accuracy: %.6f' % tuple(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_cm(cm):\n",
    "    d_size = max(len('%d' % cm.max()), len('%d' % cm.shape[1]))\n",
    "    if min(cm.shape) > 10: # make sparse\n",
    "        print('Sparse Matrix (*=diagonal)')\n",
    "        fmt_c = ', c%%0%dd%%s= %%%dd' % (d_size, d_size)\n",
    "        for i in range(cm.shape[0]):\n",
    "            s = fmt_r % i\n",
    "            for j in range(cm.shape[1]):\n",
    "                if cm[i, j] > 0:\n",
    "                    s += fmt_c % (j, '*' if i == j else ' ', cm[i, j])\n",
    "            print(s)\n",
    "    else: # make dense\n",
    "        c = '%%%dd ' % d_size\n",
    "        s = '%s| ' % (' ' * d_size)\n",
    "        s += ''.join([c % i for i in range(len(cm[0]))])\n",
    "        print(s)\n",
    "        print('-' * len(s))\n",
    "        for i, r in enumerate(cm):\n",
    "            s = '%%%dd| ' % d_size\n",
    "            s = s % i\n",
    "            s += c * len(r)\n",
    "            print(s % tuple(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_target = np.array([x.argmax() for x in y_test])\n",
    "cm = confusion_matrix(y_test_target, predictions)\n",
    "print_cm(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EI2omiec1qos"
   },
   "source": [
    "## Visualisation of cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_REk0bSz1qos"
   },
   "outputs": [],
   "source": [
    "# insert code here\n",
    "fig, ax = plt.subplots(1, 2, figsize = (18, 6))\n",
    "fig.subplots_adjust(left = 0.02, right = 0.98, wspace = 0.2)\n",
    "\n",
    "plt.rcParams.update({'font.size': 18})\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "ax[0].plot(model.history.history['accuracy'])\n",
    "ax[0].plot(model.history.history['val_accuracy'])\n",
    "ax[0].set_title('Model accuracy')\n",
    "ax[0].set_ylabel('Accuracy')\n",
    "ax[0].set_xlabel('Epoch')\n",
    "ax[0].legend(['Train', 'Validation'])\n",
    "\n",
    "# Plot training & validation loss values\n",
    "ax[1].plot(model.history.history['loss'])\n",
    "ax[1].plot(model.history.history['val_loss'])\n",
    "ax[1].set_title('Model loss')\n",
    "ax[1].set_ylabel('Loss')\n",
    "ax[1].set_xlabel('Epoch')\n",
    "ax[1].legend(['Train', 'Validation'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d1KBysuc1qou"
   },
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r2Rqvn1i1qou"
   },
   "outputs": [],
   "source": [
    "# insert code here\n",
    "check_one(X_test, predictions, actual = y_test, compare = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_ten(X_test, predictions, y_test, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RERADKgNFq9T"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "> > > > > > > > > Â© 2023 Institute of Data\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
